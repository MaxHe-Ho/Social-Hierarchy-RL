{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUGVnC0zs+towWJSdXhlAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neven-x/Social-Hierarchy-RL/blob/main/RL_Social_Hierarchy_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pettingzoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOswBwIa0z4h",
        "outputId": "1e8093b7-3822-43a5-e82b-66dbfaae91db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pettingzoo\n",
            "  Downloading pettingzoo-1.23.1-py3-none-any.whl (826 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/826.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m819.2/826.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.7/826.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo) (1.22.4)\n",
            "Collecting gymnasium>=0.28.0 (from pettingzoo)\n",
            "  Downloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (4.7.1)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, pettingzoo\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.0 pettingzoo-1.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmu7fw-JNem8",
        "outputId": "a58551c6-10ba-4cd6-c99f-29428ce62848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "import functools\n",
        "import random\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from pettingzoo.utils.env import ParallelEnv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Hierarchy_Grid(ParallelEnv):\n",
        "    metadata = {\n",
        "        \"name\": \"Hierarchy Grid\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, grid_size, num_agents, max_iter):\n",
        "        self.timestep = None\n",
        "        self.grid_size = grid_size\n",
        "        self.agents = np.arange(num_agents)\n",
        "        self.agent_positions = None\n",
        "        self.food_positions = None\n",
        "        self.food = {name: 50 for name in self.agents}\n",
        "        self.rewards = {name: 0 for name in self.agents}\n",
        "\n",
        "        self.observation_space = spaces.MultiDiscrete([self.grid_size, self.grid_size, self.num_agents + 1])\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "    def reset(self):\n",
        "        self.timestep = 0\n",
        "\n",
        "        self.agent_positions = {}\n",
        "        self.agent_position_maps = {}\n",
        "        for agent in self.agents:\n",
        "\n",
        "            agent_position = np.random.randint(0, self.grid_size, 2)\n",
        "            self.agent_positions[agent] = agent_position\n",
        "\n",
        "            agent_position_map = np.zeros((self.grid_size, self.grid_size))\n",
        "            agent_position_map[agent_position] = 1\n",
        "            self.agent_position_maps[agent] = agent_position_map\n",
        "\n",
        "        self.food_positions = [np.random.randint(0, self.grid_size, 2)]\n",
        "        self.food_position_map = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.food_position_map[self.food_positions[0]] = 1\n",
        "\n",
        "        observations = np.stack(self.agent_position_maps.values())\n",
        "        observations = np.stack([observations, self.food_position_map])\n",
        "\n",
        "        observations = {name: observations for name in self.agents}\n",
        "        return observations, {}\n",
        "\n",
        "    def step(self, actions):\n",
        "\n",
        "        self.timestep += 1\n",
        "\n",
        "        for agent in self.agents:\n",
        "            action = actions[agent]\n",
        "            self.move_agent(agent, action)\n",
        "\n",
        "        self.two_on_food_tile()\n",
        "        self.feed()\n",
        "        self.calc_reward()\n",
        "\n",
        "        if self.timestep > self.max_iter:\n",
        "          terminations = {name: True for name in self.agents}\n",
        "        else:\n",
        "          terminations = {name: False for name in self.agents}\n",
        "\n",
        "        # Add check if any agents have 0 food in which case they die\n",
        "\n",
        "        observations = np.stack(self.agent_position_maps.values())\n",
        "        observations = np.stack([observations, self.food_position_map])\n",
        "\n",
        "        observations = {name: observations for name in self.agents}\n",
        "\n",
        "        return observations, self.rewards, terminations, _, _\n",
        "\n",
        "    def move_agent(self, agent, action):\n",
        "        # Move the agent based on the selected action\n",
        "        x, y = self.agent_positions[agent]\n",
        "\n",
        "        if action == 0:  # Up\n",
        "            x -= 1\n",
        "        elif action == 1:  # Down\n",
        "            x += 1\n",
        "        elif action == 2:  # Left\n",
        "            y -= 1\n",
        "        elif action == 3:  # Right\n",
        "            y += 1\n",
        "\n",
        "        # Check if the new position is within grid boundaries\n",
        "        if 0 <= x < self.grid_size and 0 <= y < self.grid_size:\n",
        "            self.agent_positions[agent] = (x, y)\n",
        "\n",
        "\n",
        "    def feed(self):\n",
        "\n",
        "      for agent in self.agents:\n",
        "\n",
        "        if self.agent_positions[agent] in self.food_positions:\n",
        "          self.food[agent] += 3\n",
        "\n",
        "    def calc_rewards(self):\n",
        "\n",
        "      for agent in self.agents:\n",
        "\n",
        "        reward = self.food[agent] - 50\n",
        "        self.rewards[agent] += reward\n",
        "\n",
        "\n",
        "gym.register(\n",
        "    id='Hierarchy_Grid',\n",
        "    entry_point=Hierarchy_Grid,\n",
        "    kwargs={'grid_size': 10, 'num_agents': 10, 'max_iter': 200}\n",
        ")\n",
        "\n",
        "env = gym.make('Hierarchy_Grid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq_Xm1J6ysY8",
        "outputId": "216e14d0-540a-48a8-86ee-f7ecd0cd7efc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:542: UserWarning: \u001b[33mWARN: Overriding environment Hierarchy_Grid\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {spec.id}\")\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_shape, action_size):\n",
        "        def __init__(self, state_shape, action_size):\n",
        "        self.state_shape = state_shape\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 1  # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=self.state_shape))\n",
        "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma *\n",
        "                          np.amax(self.model.predict(next_state)[0]))\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)\n"
      ],
      "metadata": {
        "id": "AI6-NSubtqn5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('GridWorld')\n",
        "\n",
        "n_actions = env.action_space.n\n",
        "state_shape = (10, 10, 3)\n",
        "\n",
        "dqn = DQNAgent(state_shape, n_actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs5aN0qht1i3",
        "outputId": "61e640dc-f44f-46b6-cdb8-3e80840e770f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (10, 10)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    }
  ]
}